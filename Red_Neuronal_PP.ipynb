{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled19.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM0/+phIRaSXmgD4LYulYHR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jorge-89/Regresiones_TP_UNSAM/blob/main/Red_Neuronal_PP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EMOetFP7Mzt"
      },
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmZIU-A_7QzO",
        "outputId": "a6064295-ba75-4b68-f9f1-52349ec33c79"
      },
      "source": [
        "#se importa el set de datos\n",
        "url = 'https://raw.githubusercontent.com/Jorge-89/Regresion-Lineal-/main/base_datos_estaciones_met_V3_train.csv'\n",
        "df = pd.read_csv(url, sep=\",\")\n",
        "df.columns"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'fecha_completa', 'Fecha', 'Hora',\n",
              "       'Temp_Alicia AgriculturaCba', 'Humedad_Alicia AgriculturaCba',\n",
              "       'PP_Alicia AgriculturaCba', 'Temp_Las Varas AgriculturaCba',\n",
              "       'Humedad_Las Varas AgriculturaCba', 'PP_Las Varas AgriculturaCba',\n",
              "       'Temp_San Miguel - Establecimiento Don Luis',\n",
              "       'Humedad_San Miguel - Establecimiento Don Luis',\n",
              "       'PP_San Miguel - Establecimiento Don Luis',\n",
              "       'Temp_San Miguel - Listello', 'Humedad_San Miguel - Listello',\n",
              "       'PP_San Miguel - Listello', 'Temp_ San Miguel - Las Varillas',\n",
              "       'Humedad_ San Miguel - Las Varillas', 'PP_ San Miguel - Las Varillas'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpIl66Yt7S4l"
      },
      "source": [
        "\n",
        "x= df[[ 'PP_Las Varas AgriculturaCba', 'PP_San Miguel - Establecimiento Don Luis',\n",
        "        'PP_ San Miguel - Las Varillas']]\n",
        "y= df[\"PP_Alicia AgriculturaCba\"]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f4InWoJ7WX2"
      },
      "source": [
        "#Separo los datos de \"train\" en entrenamiento y prueba \"test\" para probar los algoritmos\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9vfNmvg2t_k"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk0J1B-y29sc"
      },
      "source": [
        "#Estandarizo las features, las redes son muy sensibles a datos no escalados.\n",
        "scaler_labels = StandardScaler()\n",
        "x_train = scaler_labels.fit_transform(x_train)\n",
        "x_test = scaler_labels.transform(x_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ6iUnZuA24Z"
      },
      "source": [
        "# Introducing the stars\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC62zNQ2BEM3"
      },
      "source": [
        "#Defino la función neuronal\n",
        "def define_model():\n",
        "    keras.backend.clear_session()\n",
        "    \n",
        "    model = keras.models.Sequential()\n",
        "\n",
        "    # Capa de entrada, con 8 variables\n",
        "    model.add(keras.layers.Flatten(input_dim=3))\n",
        "    \n",
        "\n",
        "    # 2 capas ocultas con función de activación linear, podemos usar tambien relu.\n",
        "     \n",
        "               \n",
        "    model.add(keras.layers.Dense(32, kernel_initializer='normal', activation='linear'))\n",
        "   \n",
        "    model.add(keras.layers.Dense(16, kernel_initializer='normal', activation='linear'))\n",
        "    \n",
        "\n",
        "    # Capa de salida\n",
        "    model.add(keras.layers.Dense(1, input_dim=8,kernel_initializer='normal', activation='linear'))\n",
        "    model.compile(loss='mse', metrics=['mse', 'mae'], optimizer=\"Adam\")\n",
        "\n",
        "   \n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uKRZusBAg_7"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "rA8nWv8HBqyw",
        "outputId": "cca0b0b9-f990-4cf7-c0b2-3db644b5d6a2"
      },
      "source": [
        " model = define_model()\n",
        "# Hago una corrida sin metodo de regularizacion.  \n",
        "history = model.fit(epochs=200, batch_size=30, x=x_train, y=y_train, validation_data=(x_test, y_test) )\n",
        "#                     callbacks=[early,])\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='flatten_input'), name='flatten_input', description=\"created by layer 'flatten_input'\"), but it was called on an input with incompatible shape (None, 3).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-10a8404a989b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Hago una corrida sin metodo de regularizacion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#                     callbacks=[early,])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:787 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:369 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:415 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py:254 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 8 but received input with shape (None, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU4fR6126V67"
      },
      "source": [
        "\n",
        "\n",
        "# se puede observar como el error de entrenamiento va disminuyendo, pero el de validación aumenta. Un claro sobreajuste\n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [MPG]')\n",
        "  plt.plot(hist['epoch'], hist['mae'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mae'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,1])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "  plt.plot(hist['epoch'], hist['mse'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mse'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,1])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpSS45mp9Fo5"
      },
      "source": [
        "y_pred_test = model.predict(x_test)\n",
        "y_pred_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn-63XmHZAsw"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxpDPYJp9HjW"
      },
      "source": [
        "print('Precisión del modelo usando la raíz del error cuadratico medio (RMSE):')\n",
        "score_testeo = mean_squared_error(y_test,y_pred_test,squared= True)\n",
        "\n",
        "print (score_testeo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS1BunyCDxnR"
      },
      "source": [
        "# To start from scratch, siempre aplicar esto antes de tocar otros hiperparametros o construir otro modelo, mas info en https://keras.io/api/utils/backend_utils/\n",
        "keras.backend.clear_session()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm9N4VEi83iW"
      },
      "source": [
        "#Early es un buen metodo de regularizacion, en patience aplicamos un 30 para que al menos tengan que pasar 20 epoch antes de hacer una parada.\n",
        "early = keras.callbacks.EarlyStopping(patience=30, monitor='val_loss', restore_best_weights=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAeKi8DTD8Au",
        "outputId": "5190268a-da58-4477-83a4-72a1abe1c1ba"
      },
      "source": [
        " model = define_model()\n",
        " model.compile(loss='mse', metrics=['mse', 'mae'], optimizer=\"Adam\")\n",
        " #en regresión las loss usada es mse y como metrica tambien la podemos usar, como optimizador es sumamente usado Adam\n",
        "history = model.fit(epochs=150, batch_size=32, x=x_train, y=y_train, validation_data=(x_test, y_test),\n",
        "                    callbacks=[early])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "260/260 [==============================] - 1s 2ms/step - loss: 0.0410 - mse: 0.0410 - mae: 0.0268 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0165\n",
            "Epoch 2/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0324 - mae: 0.0216 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0241\n",
            "Epoch 3/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0336 - mse: 0.0336 - mae: 0.0244 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0174\n",
            "Epoch 4/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0331 - mse: 0.0331 - mae: 0.0232 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.0246\n",
            "Epoch 5/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0330 - mse: 0.0330 - mae: 0.0241 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.0163\n",
            "Epoch 6/150\n",
            "260/260 [==============================] - 0s 1ms/step - loss: 0.0329 - mse: 0.0329 - mae: 0.0232 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0185\n",
            "Epoch 7/150\n",
            "260/260 [==============================] - 0s 1ms/step - loss: 0.0328 - mse: 0.0328 - mae: 0.0219 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0167\n",
            "Epoch 8/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0323 - mse: 0.0323 - mae: 0.0219 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0181\n",
            "Epoch 9/150\n",
            "260/260 [==============================] - 0s 1ms/step - loss: 0.0329 - mse: 0.0329 - mae: 0.0233 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.0163\n",
            "Epoch 10/150\n",
            "260/260 [==============================] - 0s 1ms/step - loss: 0.0330 - mse: 0.0330 - mae: 0.0231 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0231\n",
            "Epoch 11/150\n",
            "260/260 [==============================] - 0s 1ms/step - loss: 0.0332 - mse: 0.0332 - mae: 0.0244 - val_loss: 0.0216 - val_mse: 0.0216 - val_mae: 0.0207\n",
            "Epoch 12/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0311 - mse: 0.0311 - mae: 0.0232 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0154\n",
            "Epoch 13/150\n",
            "260/260 [==============================] - 0s 1ms/step - loss: 0.0330 - mse: 0.0330 - mae: 0.0223 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.0255\n",
            "Epoch 14/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0319 - mse: 0.0319 - mae: 0.0230 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0158\n",
            "Epoch 15/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0325 - mse: 0.0325 - mae: 0.0234 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0230\n",
            "Epoch 16/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0327 - mae: 0.0228 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0161\n",
            "Epoch 17/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0332 - mse: 0.0332 - mae: 0.0225 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0175\n",
            "Epoch 18/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0319 - mse: 0.0319 - mae: 0.0238 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.0231\n",
            "Epoch 19/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0343 - mse: 0.0343 - mae: 0.0236 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.0163\n",
            "Epoch 20/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0327 - mae: 0.0232 - val_loss: 0.0212 - val_mse: 0.0212 - val_mae: 0.0161\n",
            "Epoch 21/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0327 - mae: 0.0223 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0152\n",
            "Epoch 22/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0329 - mse: 0.0329 - mae: 0.0234 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0153\n",
            "Epoch 23/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0327 - mae: 0.0228 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0181\n",
            "Epoch 24/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0320 - mae: 0.0220 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0265\n",
            "Epoch 25/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0333 - mse: 0.0333 - mae: 0.0230 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0170\n",
            "Epoch 26/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0324 - mae: 0.0225 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0261\n",
            "Epoch 27/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0320 - mae: 0.0236 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0217\n",
            "Epoch 28/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0321 - mse: 0.0321 - mae: 0.0225 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.0185\n",
            "Epoch 29/150\n",
            "260/260 [==============================] - 0s 1ms/step - loss: 0.0326 - mse: 0.0326 - mae: 0.0217 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0169\n",
            "Epoch 30/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0329 - mse: 0.0329 - mae: 0.0232 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0223\n",
            "Epoch 31/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0327 - mae: 0.0231 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0150\n",
            "Epoch 32/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0324 - mae: 0.0221 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0155\n",
            "Epoch 33/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0323 - mse: 0.0323 - mae: 0.0228 - val_loss: 0.0216 - val_mse: 0.0216 - val_mae: 0.0215\n",
            "Epoch 34/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0329 - mse: 0.0329 - mae: 0.0226 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0149\n",
            "Epoch 35/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0331 - mse: 0.0331 - mae: 0.0229 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0223\n",
            "Epoch 36/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0327 - mae: 0.0232 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0165\n",
            "Epoch 37/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0328 - mse: 0.0328 - mae: 0.0238 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0151\n",
            "Epoch 38/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0322 - mse: 0.0322 - mae: 0.0232 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.0183\n",
            "Epoch 39/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0325 - mse: 0.0325 - mae: 0.0220 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0304\n",
            "Epoch 40/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0336 - mse: 0.0336 - mae: 0.0237 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.0202\n",
            "Epoch 41/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0326 - mse: 0.0326 - mae: 0.0232 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0165\n",
            "Epoch 42/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0324 - mae: 0.0224 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0154\n",
            "Epoch 43/150\n",
            "260/260 [==============================] - 0s 1ms/step - loss: 0.0323 - mse: 0.0323 - mae: 0.0227 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0159\n",
            "Epoch 44/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0325 - mse: 0.0325 - mae: 0.0227 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.0208\n",
            "Epoch 45/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0327 - mae: 0.0236 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.0182\n",
            "Epoch 46/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0323 - mse: 0.0323 - mae: 0.0227 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0157\n",
            "Epoch 47/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0317 - mse: 0.0317 - mae: 0.0220 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0168\n",
            "Epoch 48/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0319 - mse: 0.0319 - mae: 0.0223 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0186\n",
            "Epoch 49/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0331 - mse: 0.0331 - mae: 0.0219 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0322\n",
            "Epoch 50/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0321 - mse: 0.0321 - mae: 0.0239 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0172\n",
            "Epoch 51/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0330 - mse: 0.0330 - mae: 0.0235 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0160\n",
            "Epoch 52/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0317 - mse: 0.0317 - mae: 0.0223 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0161\n",
            "Epoch 53/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0322 - mse: 0.0322 - mae: 0.0234 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.0219\n",
            "Epoch 54/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0328 - mse: 0.0328 - mae: 0.0230 - val_loss: 0.0194 - val_mse: 0.0194 - val_mae: 0.0207\n",
            "Epoch 55/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0324 - mae: 0.0241 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0157\n",
            "Epoch 56/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0320 - mae: 0.0231 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.0155\n",
            "Epoch 57/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0325 - mse: 0.0325 - mae: 0.0217 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0185\n",
            "Epoch 58/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0322 - mse: 0.0322 - mae: 0.0222 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0175\n",
            "Epoch 59/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0322 - mse: 0.0322 - mae: 0.0231 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.0205\n",
            "Epoch 60/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0327 - mae: 0.0223 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0182\n",
            "Epoch 61/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0324 - mae: 0.0229 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0175\n",
            "Epoch 62/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0322 - mse: 0.0322 - mae: 0.0234 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0206\n",
            "Epoch 63/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0321 - mse: 0.0321 - mae: 0.0212 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0261\n",
            "Epoch 64/150\n",
            "260/260 [==============================] - 0s 1ms/step - loss: 0.0325 - mse: 0.0325 - mae: 0.0235 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0152\n",
            "Epoch 65/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0322 - mse: 0.0322 - mae: 0.0221 - val_loss: 0.0194 - val_mse: 0.0194 - val_mae: 0.0231\n",
            "Epoch 66/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0326 - mse: 0.0326 - mae: 0.0224 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.0154\n",
            "Epoch 67/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0329 - mse: 0.0329 - mae: 0.0240 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0180\n",
            "Epoch 68/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0326 - mse: 0.0326 - mae: 0.0235 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0179\n",
            "Epoch 69/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0322 - mse: 0.0322 - mae: 0.0229 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0204\n",
            "Epoch 70/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0324 - mae: 0.0229 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0152\n",
            "Epoch 71/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0319 - mse: 0.0319 - mae: 0.0220 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0250\n",
            "Epoch 72/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0319 - mse: 0.0319 - mae: 0.0229 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0170\n",
            "Epoch 73/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0326 - mse: 0.0326 - mae: 0.0228 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0150\n",
            "Epoch 74/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0323 - mse: 0.0323 - mae: 0.0233 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0156\n",
            "Epoch 75/150\n",
            "260/260 [==============================] - 0s 1ms/step - loss: 0.0324 - mse: 0.0324 - mae: 0.0221 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0191\n",
            "Epoch 76/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0330 - mse: 0.0330 - mae: 0.0224 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0292\n",
            "Epoch 77/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0325 - mse: 0.0325 - mae: 0.0231 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0153\n",
            "Epoch 78/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0322 - mse: 0.0322 - mae: 0.0225 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0193\n",
            "Epoch 79/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0327 - mae: 0.0225 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0174\n",
            "Epoch 80/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0323 - mse: 0.0323 - mae: 0.0217 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.0154\n",
            "Epoch 81/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0322 - mse: 0.0322 - mae: 0.0221 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0205\n",
            "Epoch 82/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0333 - mse: 0.0333 - mae: 0.0229 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0227\n",
            "Epoch 83/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0317 - mse: 0.0317 - mae: 0.0234 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.0186\n",
            "Epoch 84/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0324 - mae: 0.0225 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0183\n",
            "Epoch 85/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0319 - mse: 0.0319 - mae: 0.0226 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0196\n",
            "Epoch 86/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0317 - mse: 0.0317 - mae: 0.0221 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0153\n",
            "Epoch 87/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0323 - mse: 0.0323 - mae: 0.0228 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0199\n",
            "Epoch 88/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0320 - mae: 0.0224 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0167\n",
            "Epoch 89/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0320 - mae: 0.0221 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0168\n",
            "Epoch 90/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0324 - mae: 0.0226 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0162\n",
            "Epoch 91/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0313 - mse: 0.0313 - mae: 0.0225 - val_loss: 0.0212 - val_mse: 0.0212 - val_mae: 0.0240\n",
            "Epoch 92/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0323 - mse: 0.0323 - mae: 0.0225 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0157\n",
            "Epoch 93/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0317 - mse: 0.0317 - mae: 0.0218 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0228\n",
            "Epoch 94/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0319 - mse: 0.0319 - mae: 0.0227 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.0195\n",
            "Epoch 95/150\n",
            "260/260 [==============================] - 0s 2ms/step - loss: 0.0321 - mse: 0.0321 - mae: 0.0226 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "fr7r_TqAJSv1",
        "outputId": "90701159-bda2-4920-c063-905bce1659d3"
      },
      "source": [
        "# vemos como se regula el modelo evitando el sobreajuste\n",
        "\n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [MPG]')\n",
        "  plt.plot(hist['epoch'], hist['mae'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mae'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,1])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "  plt.plot(hist['epoch'], hist['mse'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mse'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,1])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18m8NYjPFm6_",
        "outputId": "ea16162a-a281-421c-820c-7dc3bb843eda"
      },
      "source": [
        "y_pred_test = model.predict(x_test)\n",
        "y_pred_test"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00869343],\n",
              "       [0.00869343],\n",
              "       [0.00869343],\n",
              "       ...,\n",
              "       [0.00869343],\n",
              "       [0.00869343],\n",
              "       [0.00869343]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwHEfaMXFstr",
        "outputId": "6b80ad3f-d99a-4f16-c4f6-e0a5c89cc822"
      },
      "source": [
        "print('Precisión del modelo usando el MSE):')\n",
        "score_testeo = mean_squared_error(y_test,y_pred_test,squared= True)\n",
        "\n",
        "print (score_testeo)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo usando el MSE):\n",
            "0.019420160751602255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXjMPPfrGosY"
      },
      "source": [
        "#Veamos como se comporta el modelo con CV y con hiperparametros obtenidos de GriSearchCV \n",
        "   \n",
        "    # To start from scratch\n",
        "keras.backend.clear_session()\n",
        "#Luego de tener un modelo con regularización es conveniente usar un CV y tener un mse para ver como se comporta con datos que nunca observo.\n",
        "regressor = KerasRegressor(build_fn = define_model, batch_size = 32, epochs = 58)\n",
        "errores = cross_val_score(regressor, x_test, y_test, cv = 5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "errores = -errores\n",
        "errores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFsSpQF1PRRj"
      },
      "source": [
        "#Un MSE promedio parecido al obtenido con early, no se observa mucha varianza en los 5 errores del CV\n",
        "print(errores.mean(), errores.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_04EK_8iDGrJ"
      },
      "source": [
        "**Esta parte es opcional, ya que se construye una grilla para saber que hiperparametros pueden ser mejores, pero consume al menos 1 hora.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31SWQmtmZWyh"
      },
      "source": [
        "def define_model(optimizer,activation):\n",
        "    keras.backend.clear_session()\n",
        "    \n",
        "    model = keras.models.Sequential()\n",
        "\n",
        "    # Input layer\n",
        "    model.add(keras.layers.Flatten(input_dim=8))\n",
        "    \n",
        "\n",
        "    # Two hidden layers with 32 units each\n",
        "    model.add(keras.layers.Dense(64, kernel_initializer='normal', activation='relu'))\n",
        "    \n",
        "               \n",
        "    model.add(keras.layers.Dense(32, kernel_initializer='normal', activation='relu'))\n",
        "   \n",
        "    model.add(keras.layers.Dense(16, kernel_initializer='normal', activation='relu'))\n",
        "    \n",
        "\n",
        "    # Output layer. As this is a multi-class classification problem, use K (here 10) units.\n",
        "    model.add(keras.layers.Dense(1, input_dim=8,kernel_initializer='normal', activation='relu'))\n",
        "    model.compile(loss='mse', metrics=['mse', 'mae'], optimizer=optimizer)\n",
        "\n",
        "   \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvuoMM1Ktq-p"
      },
      "source": [
        "keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yV5Sm02W2Wm"
      },
      "source": [
        "\n",
        "regressor = KerasRegressor(build_fn = define_model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR9OYvWeXFg1"
      },
      "source": [
        "parameters= {\"batch_size\": [25,32], \"epochs\":[100,200], \"optimizer\":[\"Adam\", \"rmsprop\"], \"activation\":[\"relu\",\"linear\"]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byQqlBzmXt3j"
      },
      "source": [
        "grilla = GridSearchCV(estimator=regressor, param_grid= parameters,scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
        "                      \n",
        "                      \n",
        "grilla.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykl9x6TjYQi1"
      },
      "source": [
        "grilla.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czU4nMhBYZBL"
      },
      "source": [
        "grilla.best_score_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbX5fx-GbHiU"
      },
      "source": [
        "# Fit best model\n",
        "modelo=grilla.best_estimator_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQp77t7ebKy7"
      },
      "source": [
        "\n",
        "#se puede usar scoring='neg_root_mean_squared_error' tambien que seria la raiz\n",
        "MSE_modelo=cross_val_score(modelo,x_test,y_test,cv=5,scoring='neg_mean_squared_error')\n",
        "errores = -MSE_modelo\n",
        "MSE_modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeaAnEALiVhW"
      },
      "source": [
        "print(errores.mean(), errores.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v4lj95aWVRH"
      },
      "source": [
        "Ahora se prueba con un set de datos final de la materia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM58eaPWWW4q",
        "outputId": "07d5dcaf-4f21-4b6a-e695-f15668f1254f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#se importa el set de datos\n",
        "url = 'https://raw.githubusercontent.com/Jorge-89/Regresiones_TP_UNSAM/main/base_datos_estaciones_met_V3_test.csv'\n",
        "df = pd.read_csv(url, sep=\",\")\n",
        "df.columns"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'fecha_completa', 'Fecha', 'Hora',\n",
              "       'Temp_Alicia AgriculturaCba', 'Humedad_Alicia AgriculturaCba',\n",
              "       'PP_Alicia AgriculturaCba', 'Temp_Las Varas AgriculturaCba',\n",
              "       'Humedad_Las Varas AgriculturaCba', 'PP_Las Varas AgriculturaCba',\n",
              "       'Temp_San Miguel - Establecimiento Don Luis',\n",
              "       'Humedad_San Miguel - Establecimiento Don Luis',\n",
              "       'PP_San Miguel - Establecimiento Don Luis',\n",
              "       'Temp_San Miguel - Listello', 'Humedad_San Miguel - Listello',\n",
              "       'PP_San Miguel - Listello', 'Temp_ San Miguel - Las Varillas',\n",
              "       'Humedad_ San Miguel - Las Varillas', 'PP_ San Miguel - Las Varillas'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka8yawmsQw9F"
      },
      "source": [
        "x= df[[ 'PP_Las Varas AgriculturaCba', 'PP_San Miguel - Establecimiento Don Luis',\n",
        "        'PP_ San Miguel - Las Varillas']]\n",
        "y= df[\"PP_Alicia AgriculturaCba\"]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkk2arZ1X2-Y"
      },
      "source": [
        "keras.backend.clear_session()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRZL6ToAWlMG"
      },
      "source": [
        "#Estandarizo las features, las redes son muy sensibles a datos no escalados.\n",
        "scaler_labels = StandardScaler()\n",
        "x = scaler_labels.fit_transform(x)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K0mxTFXRDRc",
        "outputId": "c5247374-5eeb-4fa9-cb95-e5fb73e14eb2"
      },
      "source": [
        "y_p = model.predict(x)\n",
        "y_p"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00091707],\n",
              "       [0.00091707],\n",
              "       [0.00091707],\n",
              "       ...,\n",
              "       [0.00091707],\n",
              "       [0.00091708],\n",
              "       [0.00091708]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcU9N4sERDms",
        "outputId": "e2118795-35e1-4224-e6cb-a5efd6298538"
      },
      "source": [
        "y"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0.0\n",
              "1       0.0\n",
              "2       0.0\n",
              "3       0.0\n",
              "4       0.0\n",
              "       ... \n",
              "2587    0.0\n",
              "2588    0.0\n",
              "2589    0.0\n",
              "2590    0.0\n",
              "2591    0.0\n",
              "Name: PP_Alicia AgriculturaCba, Length: 2592, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGeIwCcBXXiX",
        "outputId": "5cea1d8f-ea13-40f1-c6fc-a2e759bc5455",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Precisión del modelo usando la raíz del error cuadratico medio (RMSE):')\n",
        "score_testeo = mean_squared_error(y,y_p,squared= True)\n",
        "\n",
        "print (score_testeo)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo usando la raíz del error cuadratico medio (RMSE):\n",
            "0.03740690628818065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qUkszeObcQX"
      },
      "source": [
        "data_predicha = pd.DataFrame(y_p)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWMcTPUXbfr2"
      },
      "source": [
        "data_test = pd.DataFrame(y)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ucaZhuKb-RO"
      },
      "source": [
        "\n",
        "result = pd.concat([data_predicha, data_test], axis=1)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E4SjHaSc61I"
      },
      "source": [
        "result.to_csv(\"comparacion.csv\")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HwMACg1cZPw",
        "outputId": "d88c785c-7891-4348-f3f4-c06aebbc628e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('comparacion.csv')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0a3762fc-b8d1-4449-8343-feefbba45241\", \"comparacion.csv\", 55696)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}